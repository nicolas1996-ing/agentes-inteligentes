{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOQlhirgAgrCP6TQe449WT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolas1996-ing/agentes-inteligentes/blob/main/sistemas_inteligentes_laboratorio_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Importaciones**"
      ],
      "metadata": {
        "id": "4fXmMwf728OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -U langchain-google-genai langgraph langchain-core langchain-community"
      ],
      "metadata": {
        "id": "oLtrboX_2M3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, Sequence\n",
        "import operator\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "1qA2O4XT18f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Cargar api key Gemini**"
      ],
      "metadata": {
        "id": "fRWdXbQ63CQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "try:\n",
        "  GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "  print(\"API_KEY de Gemini cargada correctamente\")\n",
        "except Exception as e:\n",
        "  print(\"Error al cargar API_KEY. Configura en > Runtime > Manage secrets\")\n",
        "  print(\"Nombre del secreto: GOOGLE_API_KEY\")\n",
        "  raise e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsKgHRvhxUq0",
        "outputId": "7d1c379f-162c-46ab-ae66-4a3c15eb4ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API_KEY de Gemini cargada correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Consultar modelos disponibles**"
      ],
      "metadata": {
        "id": "71_yzf8i3LT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.generativeai import list_models\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "models = list_models()\n",
        "print(\"Modelos disponibles: \")\n",
        "for model in models:\n",
        "  print(f\"{model.name} | Métodos soportados: {model.supported_generation_methods}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "collapsed": true,
        "id": "-0nX7-5aycGm",
        "outputId": "5ec3d19b-ee23-4bf4-cd1e-00ce92007eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelos disponibles: \n",
            "models/embedding-gecko-001 | Métodos soportados: ['embedText', 'countTextTokens']\n",
            "models/gemini-2.5-flash | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-pro | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-exp | Métodos soportados: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-001 | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-exp-image-generation | Métodos soportados: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash-lite-001 | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite-preview-02-05 | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite-preview | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-exp-1206 | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-preview-tts | Métodos soportados: ['countTokens', 'generateContent']\n",
            "models/gemini-2.5-pro-preview-tts | Métodos soportados: ['countTokens', 'generateContent']\n",
            "models/gemma-3-1b-it | Métodos soportados: ['generateContent', 'countTokens']\n",
            "models/gemma-3-4b-it | Métodos soportados: ['generateContent', 'countTokens']\n",
            "models/gemma-3-12b-it | Métodos soportados: ['generateContent', 'countTokens']\n",
            "models/gemma-3-27b-it | Métodos soportados: ['generateContent', 'countTokens']\n",
            "models/gemma-3n-e4b-it | Métodos soportados: ['generateContent', 'countTokens']\n",
            "models/gemma-3n-e2b-it | Métodos soportados: ['generateContent', 'countTokens']\n",
            "models/gemini-flash-latest | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-flash-lite-latest | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-pro-latest | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-lite | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-image-preview | Métodos soportados: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-image | Métodos soportados: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-preview-09-2025 | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-lite-preview-09-2025 | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-3-pro-preview | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-3-pro-image-preview | Métodos soportados: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "models/nano-banana-pro-preview | Métodos soportados: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "models/gemini-robotics-er-1.5-preview | Métodos soportados: ['generateContent', 'countTokens']\n",
            "models/gemini-2.5-computer-use-preview-10-2025 | Métodos soportados: ['generateContent', 'countTokens']\n",
            "models/embedding-001 | Métodos soportados: ['embedContent']\n",
            "models/text-embedding-004 | Métodos soportados: ['embedContent']\n",
            "models/gemini-embedding-exp-03-07 | Métodos soportados: ['embedContent', 'countTextTokens', 'countTokens']\n",
            "models/gemini-embedding-exp | Métodos soportados: ['embedContent', 'countTextTokens', 'countTokens']\n",
            "models/gemini-embedding-001 | Métodos soportados: ['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent']\n",
            "models/aqa | Métodos soportados: ['generateAnswer']\n",
            "models/imagen-4.0-generate-preview-06-06 | Métodos soportados: ['predict']\n",
            "models/imagen-4.0-ultra-generate-preview-06-06 | Métodos soportados: ['predict']\n",
            "models/imagen-4.0-generate-001 | Métodos soportados: ['predict']\n",
            "models/imagen-4.0-ultra-generate-001 | Métodos soportados: ['predict']\n",
            "models/imagen-4.0-fast-generate-001 | Métodos soportados: ['predict']\n",
            "models/veo-2.0-generate-001 | Métodos soportados: ['predictLongRunning']\n",
            "models/veo-3.0-generate-001 | Métodos soportados: ['predictLongRunning']\n",
            "models/veo-3.0-fast-generate-001 | Métodos soportados: ['predictLongRunning']\n",
            "models/veo-3.1-generate-preview | Métodos soportados: ['predictLongRunning']\n",
            "models/veo-3.1-fast-generate-preview | Métodos soportados: ['predictLongRunning']\n",
            "models/gemini-2.0-flash-live-001 | Métodos soportados: ['bidiGenerateContent', 'countTokens']\n",
            "models/gemini-live-2.5-flash-preview | Métodos soportados: ['bidiGenerateContent', 'countTokens']\n",
            "models/gemini-2.5-flash-live-preview | Métodos soportados: ['bidiGenerateContent', 'countTokens']\n",
            "models/gemini-2.5-flash-native-audio-latest | Métodos soportados: ['countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.5-flash-native-audio-preview-09-2025 | Métodos soportados: ['countTokens', 'bidiGenerateContent']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Definir esquema de estado**"
      ],
      "metadata": {
        "id": "yhX8MHO3zu7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, Sequence\n",
        "import operator\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[Sequence[dict], operator.add]\n",
        "  current_step: str\n",
        "  analysis_results: dict"
      ],
      "metadata": {
        "id": "dgJNpDqcy3sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Inicializar LLM**"
      ],
      "metadata": {
        "id": "KdGFOeZ1z3m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = 'gemini-2.5-flash',\n",
        "    temperature = 0.3,\n",
        "    google_api_key = GOOGLE_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "vmWvdE1fzjtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Funciones con inyección de dependencias**"
      ],
      "metadata": {
        "id": "WgpNnU5E3hhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_input_gemini(state: AgentState, llm_instance):\n",
        "  \"\"\"Nodo que analiza la entrada usando Gemini\"\"\"\n",
        "  messages = state['messages']\n",
        "  gemini_messages = [\n",
        "      {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"Eres un analista experto. Analiza la solicitud del usuario y determina qué tipo de ayuda necesita.\"\n",
        "      },\n",
        "      *messages\n",
        "  ]\n",
        "  response = llm_instance.invoke(gemini_messages)\n",
        "  print(f\"Analisis completado: {response.content[:100]}...\")\n",
        "\n",
        "  return {\n",
        "      \"current_step\": \"analysis_complete\",\n",
        "      \"analysis_results\": {\n",
        "          \"intent\": \"technical_support\",\n",
        "          \"confidence\": 0.92,\n",
        "          \"details\": response.content\n",
        "      }\n",
        "  }\n",
        "\n",
        "def generate_response_gemini(state: AgentState, llm_instance):\n",
        "  \"\"\"Nodo que genera una respuesta usando Gemini\"\"\"\n",
        "  messages = state['messages']\n",
        "  analysis = state['analysis_results']\n",
        "  system_prompt = f\"\"\"\n",
        "  Eres un asistente técnico experto. El análisis indica:\n",
        "  - Intención: {analysis['intent']}\n",
        "  - Confianza: {analysis['confidence']:.2f}\n",
        "  - Detalles: {analysis['details'][:200]}\n",
        "\n",
        "  Proporciona una respuesta clara, técnica y útil. Se conciso pero completo.\n",
        "  \"\"\"\n",
        "\n",
        "  gemini_messages = [\n",
        "      {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": system_prompt\n",
        "      },\n",
        "      *messages\n",
        "  ]\n",
        "\n",
        "  response = llm_instance.invoke(gemini_messages)\n",
        "\n",
        "  print(f\"Respuesta generada: {response.content[:100]}...\")\n",
        "\n",
        "  return {\n",
        "      \"current_step\": \"response_generated\",\n",
        "      \"messages\": [\n",
        "          {\n",
        "              \"role\": \"assistant\",\n",
        "              \"content\": system_prompt\n",
        "          },\n",
        "          *messages\n",
        "      ]\n",
        "  }\n"
      ],
      "metadata": {
        "id": "ch0SeZeu3o1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Crear wrappers para el grafo**"
      ],
      "metadata": {
        "id": "VN-4t2lz6Kn_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "123f1b77"
      },
      "source": [
        "Esta es la forma estándar de importar clases o funciones específicas de un módulo en Python. Asegúrate de que la biblioteca `langchain-google-genai` esté instalada en tu entorno (usando `!pip install langchain-google-genai`) antes de intentar importarla."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_node(state):\n",
        "  return analyze_input_gemini(state, llm)\n",
        "\n",
        "def respond_node(state):\n",
        "  return generate_response_gemini(state, llm)"
      ],
      "metadata": {
        "id": "X1Q4ztE-34lP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Construir el grafo**"
      ],
      "metadata": {
        "id": "vnrRUT9m7Hm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"analyze\", analyze_node)\n",
        "workflow.add_node(\"respond\", respond_node)\n",
        "workflow.add_edge(START, \"analyze\")\n",
        "workflow.add_edge(\"analyze\", \"respond\")\n",
        "workflow.add_edge(\"respond\", END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVWv7d7y7L94",
        "outputId": "bab15082-ccef-4aa5-a8b5-d334f31594e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78feded56450>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Compilar con checkpointing**"
      ],
      "metadata": {
        "id": "iMuKJQ_X7gU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "ipWOey1A7Wae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Ejecutar en tiempo real**"
      ],
      "metadata": {
        "id": "BU0SbBCK74CJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = { \"configurable\": { \"thread_id\": \"colab_test_1\" } }\n",
        "initial_state = {\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"¿Qué es un grafo y como se relacion con langgraph?\"\n",
        "        }\n",
        "    ],\n",
        "    \"current_step\": \"initial\",\n",
        "    \"analysis_results\": {}\n",
        "}\n",
        "\n",
        "print(\"Ejecutando agente con Gemini en LangGraph...\")\n",
        "result = app.invoke(initial_state, config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C3CnQaX08HXY",
        "outputId": "819d7e84-1765-47a8-d890-db13904a06cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejecutando agente con Gemini en LangGraph...\n",
            "Analisis completado: Eres un experto en IA, y la relación entre grafos y LangGraph es fundamental para entender cómo cons...\n",
            "Respuesta generada: Un **grafo** es una estructura matemática utilizada para modelar relaciones entre objetos. Consiste ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Mostrar resultados**"
      ],
      "metadata": {
        "id": "H_axrYBv83bK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RESULTADO FINAL DEL AGENTE\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Paso actual: {result['current_step']}\")\n",
        "\n",
        "print(json.dumps(result['analysis_results'], indent=4, ensure_ascii=False))\n",
        "print(json.dumps(result['analysis_results'], indent=2, ensure_ascii=False))\n",
        "\n",
        "print(\"\\n RESPUESTA DEL AGENTE:\")\n",
        "print(result[\"messages\"][-1][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wynepuc8xGo",
        "outputId": "bd22ccbe-210e-4e18-c948-91c70a4aa976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RESULTADO FINAL DEL AGENTE\n",
            "==================================================\n",
            "Paso actual: response_generated\n",
            "{\n",
            "    \"intent\": \"technical_support\",\n",
            "    \"confidence\": 0.92,\n",
            "    \"details\": \"Eres un experto en IA, y la relación entre grafos y LangGraph es fundamental para entender cómo construir aplicaciones LLM complejas y robustas. Aquí tienes un análisis detallado:\\n\\n---\\n\\n## Análisis: Qué es un Grafo y su Relación con LangGraph\\n\\n### 1. ¿Qué es un Grafo?\\n\\nEn ciencias de la computación y matemáticas, un **grafo** es una estructura de datos abstracta que se utiliza para representar un conjunto de objetos y las relaciones entre ellos. Es una de las estructuras de datos más fundamentales y versátiles.\\n\\nUn grafo consta de dos componentes principales:\\n\\n1.  **Nodos (o Vértices):** Representan los objetos o entidades individuales. Piensa en ellos como los puntos en un mapa.\\n    *   *Ejemplos:* Ciudades, personas en una red social, páginas web, estados en un proceso, componentes de un sistema.\\n\\n2.  **Aristas (o Bordes):** Representan las conexiones o relaciones entre los nodos. Piensa en ellas como las líneas que conectan los puntos en un mapa.\\n    *   *Ejemplos:* Carreteras entre ciudades, amistades entre personas, enlaces de hipertexto entre páginas web, transiciones entre estados.\\n\\n**Características importantes de los grafos:**\\n\\n*   **Dirigidos vs. No Dirigidos:**\\n    *   **No Dirigidos:** La relación es bidireccional (si A está conectado a B, B está conectado a A). Ejemplo: Una amistad en Facebook.\\n    *   **Dirigidos:** La relación tiene una dirección específica (si A está conectado a B, no significa necesariamente que B esté conectado a A). Ejemplo: Un seguidor en Twitter (A sigue a B, pero B no sigue necesariamente a A).\\n*   **Ponderados vs. No Ponderados:**\\n    *   **Ponderados:** Las aristas tienen un \\\"peso\\\" o valor asociado (por ejemplo, la distancia de una carretera, el costo de un vuelo).\\n    *   **No Ponderados:** Las aristas simplemente indican una conexión, sin un valor adicional.\\n*   **Cíclicos vs. Acíclicos:**\\n    *   **Cíclicos:** Un grafo contiene un camino que comienza y termina en el mismo nodo.\\n    *   **Acíclicos:** No existen ciclos.\\n\\n**¿Por qué son útiles los grafos?**\\nSon extremadamente poderosos para modelar problemas donde las entidades tienen relaciones complejas entre sí, como redes de comunicación, rutas de navegación, dependencias de tareas, redes sociales y, como veremos, flujos de ejecución en aplicaciones.\\n\\n### 2. ¿Cómo se Relaciona un Grafo con LangGraph?\\n\\n**LangGraph** es una biblioteca construida sobre LangChain que permite construir aplicaciones LLM (Large Language Model) stateful y multi-agente. Su característica distintiva es que utiliza el **paradigma de grafos dirigidos acíclicos (o a veces cíclicos, para agentes iterativos)** para definir y gestionar el flujo de ejecución de una aplicación.\\n\\nEn LangGraph, la relación es directa y fundamental:\\n\\n1.  **Nodos en LangGraph = Pasos o Unidades de Trabajo:**\\n    *   Cada nodo en un grafo de LangGraph representa una operación o un \\\"paso\\\" en tu aplicación LLM.\\n    *   Estos pasos pueden ser:\\n        *   Una llamada a un LLM (un prompt a GPT-4).\\n        *   La invocación de una herramienta (una búsqueda en la web, una llamada a una API).\\n        *   Un agente completo que toma decisiones y ejecuta tareas.\\n        *   Lógica condicional (un nodo que decide el siguiente paso basándose en un resultado).\\n        *   Una función personalizada que procesa datos.\\n    *   Cada nodo recibe el estado actual del grafo como entrada, realiza su operación y devuelve una actualización a ese estado.\\n\\n2.  **Aristas en LangGraph = Transiciones o Flujos de Control:**\\n    *   Las aristas definen cómo se mueve el flujo de ejecución entre los nodos. Siempre son **dirigidas**.\\n    *   Pueden ser de dos tipos principales:\\n        *   **Aristas Fijas (o \\\"Direct Edges\\\"):** Después del Nodo A, siempre ir al Nodo B.\\n        *   **Aristas Condicionales (o \\\"Conditional Edges\\\"):** Después del Nodo A, evaluar su salida y, basándose en ella, decidir a qué Nodo B, C o D ir. Esta es una de las características más potentes de LangGraph, permitiendo una lógica de ramificación dinámica.\\n\\n3.  **Estado del Grafo = Contexto Compartido:**\\n    *   LangGraph mantiene un objeto de \\\"estado\\\" global (a menudo un `TypedDict`) que se pasa y se actualiza a medida que el control fluye de un nodo a otro.\\n    *   Este estado actúa como la memoria o el contexto compartido de toda la aplicación, permitiendo que la información generada en un paso sea utilizada en pasos posteriores.\\n\\n4.  **Ciclos en LangGraph = Iteración y Comportamiento Agéntico:**\\n    *   Mientras que muchos sistemas de flujo de trabajo se basan en DAGs (Grafos Acíclicos Dirigidos), LangGraph permite explícitamente **ciclos**.\\n    *   Esto es crucial para construir agentes que pueden \\\"pensar, actuar y observar\\\" de forma iterativa, autocorregirse o intentar múltiples veces hasta alcanzar un objetivo. Un ciclo permite que el flujo de ejecución regrese a un nodo anterior, modificando el estado en cada iteración, hasta que se cumpla una condición de salida.\\n\\n**Ejemplo de cómo un grafo modela una aplicación LLM con LangGraph:**\\n\\nImagina un agente de reserva de vuelos:\\n\\n*   **Nodos:**\\n    *   `ParsearSolicitud`: Un LLM que extrae la intención y parámetros del usuario (origen, destino, fechas).\\n    *   `BuscarVuelos`: Una herramienta que consulta una API de vuelos.\\n    *   `ConfirmarInfo`: Un LLM que genera una respuesta amigable y pide confirmación al usuario.\\n    *   `ManejarError`: Un LLM que gestiona errores o ambigüedades.\\n*   **Aristas:**\\n    *   Del nodo `ParsearSolicitud`, una arista condicional:\\n        *   Si la solicitud es clara y los parámetros están presentes -> ir a `BuscarVuelos`.\\n        *   Si faltan parámetros o hay ambigüedad -> ir a `ManejarError`.\\n    *   Del nodo `BuscarVuelos`, una arista condicional:\\n        *   Si se encuentran vuelos -> ir a `ConfirmarInfo`.\\n        *   Si no se encuentran vuelos o hay un error -> ir a `ManejarError`.\\n    *   Del nodo `ManejarError`, una arista que podría regresar a `ParsearSolicitud` para pedir más información, creando un **ciclo** para la clarificación.\\n\\n**Beneficios de usar el paradigma de grafos para LangGraph:**\\n\\n*   **Claridad y Visualización:** Es fácil entender y visualizar el flujo de la aplicación.\\n*   **Modularidad:** Cada nodo es una unidad de trabajo encapsulada, lo que facilita la prueba y el mantenimiento.\\n*   **Gestión de Estado Robusta:** El estado compartido permite que la información fluya coherentemente a través de la aplicación.\\n*   **Lógica Condicional Compleja:** Permite ramificaciones y decisiones dinámicas basadas en los resultados de los LLM o herramientas.\\n*   **Comportamiento Agéntico Iterativo:** La capacidad de crear ciclos es fundamental para agentes que requieren múltiples \\\"turnos\\\" para resolver un problema, emulando un bucle de pensamiento/acción/observación.\\n*   **Depuración:** Facilita el seguimiento de la ejecución y la identificación de problemas.\\n\\nEn resumen, LangGraph adopta el modelo de grafos porque es una forma extraordinariamente eficaz y flexible de diseñar, construir y ejecutar aplicaciones LLM complejas que necesitan gestionar estado, tomar decisiones condicionales y operar de manera iterativa, como los agentes autónomos. Es el esqueleto lógico sobre el cual se construyen estas aplicaciones inteligentes.\"\n",
            "}\n",
            "{\n",
            "  \"intent\": \"technical_support\",\n",
            "  \"confidence\": 0.92,\n",
            "  \"details\": \"Eres un experto en IA, y la relación entre grafos y LangGraph es fundamental para entender cómo construir aplicaciones LLM complejas y robustas. Aquí tienes un análisis detallado:\\n\\n---\\n\\n## Análisis: Qué es un Grafo y su Relación con LangGraph\\n\\n### 1. ¿Qué es un Grafo?\\n\\nEn ciencias de la computación y matemáticas, un **grafo** es una estructura de datos abstracta que se utiliza para representar un conjunto de objetos y las relaciones entre ellos. Es una de las estructuras de datos más fundamentales y versátiles.\\n\\nUn grafo consta de dos componentes principales:\\n\\n1.  **Nodos (o Vértices):** Representan los objetos o entidades individuales. Piensa en ellos como los puntos en un mapa.\\n    *   *Ejemplos:* Ciudades, personas en una red social, páginas web, estados en un proceso, componentes de un sistema.\\n\\n2.  **Aristas (o Bordes):** Representan las conexiones o relaciones entre los nodos. Piensa en ellas como las líneas que conectan los puntos en un mapa.\\n    *   *Ejemplos:* Carreteras entre ciudades, amistades entre personas, enlaces de hipertexto entre páginas web, transiciones entre estados.\\n\\n**Características importantes de los grafos:**\\n\\n*   **Dirigidos vs. No Dirigidos:**\\n    *   **No Dirigidos:** La relación es bidireccional (si A está conectado a B, B está conectado a A). Ejemplo: Una amistad en Facebook.\\n    *   **Dirigidos:** La relación tiene una dirección específica (si A está conectado a B, no significa necesariamente que B esté conectado a A). Ejemplo: Un seguidor en Twitter (A sigue a B, pero B no sigue necesariamente a A).\\n*   **Ponderados vs. No Ponderados:**\\n    *   **Ponderados:** Las aristas tienen un \\\"peso\\\" o valor asociado (por ejemplo, la distancia de una carretera, el costo de un vuelo).\\n    *   **No Ponderados:** Las aristas simplemente indican una conexión, sin un valor adicional.\\n*   **Cíclicos vs. Acíclicos:**\\n    *   **Cíclicos:** Un grafo contiene un camino que comienza y termina en el mismo nodo.\\n    *   **Acíclicos:** No existen ciclos.\\n\\n**¿Por qué son útiles los grafos?**\\nSon extremadamente poderosos para modelar problemas donde las entidades tienen relaciones complejas entre sí, como redes de comunicación, rutas de navegación, dependencias de tareas, redes sociales y, como veremos, flujos de ejecución en aplicaciones.\\n\\n### 2. ¿Cómo se Relaciona un Grafo con LangGraph?\\n\\n**LangGraph** es una biblioteca construida sobre LangChain que permite construir aplicaciones LLM (Large Language Model) stateful y multi-agente. Su característica distintiva es que utiliza el **paradigma de grafos dirigidos acíclicos (o a veces cíclicos, para agentes iterativos)** para definir y gestionar el flujo de ejecución de una aplicación.\\n\\nEn LangGraph, la relación es directa y fundamental:\\n\\n1.  **Nodos en LangGraph = Pasos o Unidades de Trabajo:**\\n    *   Cada nodo en un grafo de LangGraph representa una operación o un \\\"paso\\\" en tu aplicación LLM.\\n    *   Estos pasos pueden ser:\\n        *   Una llamada a un LLM (un prompt a GPT-4).\\n        *   La invocación de una herramienta (una búsqueda en la web, una llamada a una API).\\n        *   Un agente completo que toma decisiones y ejecuta tareas.\\n        *   Lógica condicional (un nodo que decide el siguiente paso basándose en un resultado).\\n        *   Una función personalizada que procesa datos.\\n    *   Cada nodo recibe el estado actual del grafo como entrada, realiza su operación y devuelve una actualización a ese estado.\\n\\n2.  **Aristas en LangGraph = Transiciones o Flujos de Control:**\\n    *   Las aristas definen cómo se mueve el flujo de ejecución entre los nodos. Siempre son **dirigidas**.\\n    *   Pueden ser de dos tipos principales:\\n        *   **Aristas Fijas (o \\\"Direct Edges\\\"):** Después del Nodo A, siempre ir al Nodo B.\\n        *   **Aristas Condicionales (o \\\"Conditional Edges\\\"):** Después del Nodo A, evaluar su salida y, basándose en ella, decidir a qué Nodo B, C o D ir. Esta es una de las características más potentes de LangGraph, permitiendo una lógica de ramificación dinámica.\\n\\n3.  **Estado del Grafo = Contexto Compartido:**\\n    *   LangGraph mantiene un objeto de \\\"estado\\\" global (a menudo un `TypedDict`) que se pasa y se actualiza a medida que el control fluye de un nodo a otro.\\n    *   Este estado actúa como la memoria o el contexto compartido de toda la aplicación, permitiendo que la información generada en un paso sea utilizada en pasos posteriores.\\n\\n4.  **Ciclos en LangGraph = Iteración y Comportamiento Agéntico:**\\n    *   Mientras que muchos sistemas de flujo de trabajo se basan en DAGs (Grafos Acíclicos Dirigidos), LangGraph permite explícitamente **ciclos**.\\n    *   Esto es crucial para construir agentes que pueden \\\"pensar, actuar y observar\\\" de forma iterativa, autocorregirse o intentar múltiples veces hasta alcanzar un objetivo. Un ciclo permite que el flujo de ejecución regrese a un nodo anterior, modificando el estado en cada iteración, hasta que se cumpla una condición de salida.\\n\\n**Ejemplo de cómo un grafo modela una aplicación LLM con LangGraph:**\\n\\nImagina un agente de reserva de vuelos:\\n\\n*   **Nodos:**\\n    *   `ParsearSolicitud`: Un LLM que extrae la intención y parámetros del usuario (origen, destino, fechas).\\n    *   `BuscarVuelos`: Una herramienta que consulta una API de vuelos.\\n    *   `ConfirmarInfo`: Un LLM que genera una respuesta amigable y pide confirmación al usuario.\\n    *   `ManejarError`: Un LLM que gestiona errores o ambigüedades.\\n*   **Aristas:**\\n    *   Del nodo `ParsearSolicitud`, una arista condicional:\\n        *   Si la solicitud es clara y los parámetros están presentes -> ir a `BuscarVuelos`.\\n        *   Si faltan parámetros o hay ambigüedad -> ir a `ManejarError`.\\n    *   Del nodo `BuscarVuelos`, una arista condicional:\\n        *   Si se encuentran vuelos -> ir a `ConfirmarInfo`.\\n        *   Si no se encuentran vuelos o hay un error -> ir a `ManejarError`.\\n    *   Del nodo `ManejarError`, una arista que podría regresar a `ParsearSolicitud` para pedir más información, creando un **ciclo** para la clarificación.\\n\\n**Beneficios de usar el paradigma de grafos para LangGraph:**\\n\\n*   **Claridad y Visualización:** Es fácil entender y visualizar el flujo de la aplicación.\\n*   **Modularidad:** Cada nodo es una unidad de trabajo encapsulada, lo que facilita la prueba y el mantenimiento.\\n*   **Gestión de Estado Robusta:** El estado compartido permite que la información fluya coherentemente a través de la aplicación.\\n*   **Lógica Condicional Compleja:** Permite ramificaciones y decisiones dinámicas basadas en los resultados de los LLM o herramientas.\\n*   **Comportamiento Agéntico Iterativo:** La capacidad de crear ciclos es fundamental para agentes que requieren múltiples \\\"turnos\\\" para resolver un problema, emulando un bucle de pensamiento/acción/observación.\\n*   **Depuración:** Facilita el seguimiento de la ejecución y la identificación de problemas.\\n\\nEn resumen, LangGraph adopta el modelo de grafos porque es una forma extraordinariamente eficaz y flexible de diseñar, construir y ejecutar aplicaciones LLM complejas que necesitan gestionar estado, tomar decisiones condicionales y operar de manera iterativa, como los agentes autónomos. Es el esqueleto lógico sobre el cual se construyen estas aplicaciones inteligentes.\"\n",
            "}\n",
            "\n",
            " RESPUESTA DEL AGENTE:\n",
            "¿Qué es un grafo y como se relacion con langgraph?\n"
          ]
        }
      ]
    }
  ]
}